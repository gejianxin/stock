{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "# import numba as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def strided_app(origin_array: np.ndarray,\n",
    "                window: int = 252, step=1) -> np.ndarray:\n",
    "    if origin_array.size > window:\n",
    "        nrows = ((origin_array.size - window) // step) + 1\n",
    "    else:\n",
    "        return origin_array\n",
    "    n = origin_array.strides[0]\n",
    "    return np.lib.stride_tricks.as_strided(origin_array,\n",
    "                                           shape=(nrows, window),\n",
    "                                           strides=(step * n, n))\n",
    "\n",
    "def rolling_poly9(origin_array: np.ndarray, window: int = 252) -> np.ndarray:\n",
    "    '''\n",
    "    一次九项式滚动分解拟合\n",
    "    '''\n",
    "    index = range(window)\n",
    "\n",
    "    def last_poly9(array_input):\n",
    "        fit_params = np.polynomial.Chebyshev.fit(index, array_input, 9)\n",
    "        return fit_params(index)[-1]\n",
    "\n",
    "    if (len(origin_array) > window):\n",
    "        stride_matrix = strided_app(origin_array, window, 1)\n",
    "        # numpy.r_[]按照行方向拼接array，list是列向量形式存储，故仅能拼接array\n",
    "        # numpy.c_[]按照列方向拼接array\n",
    "        # .full()填充ndarray\n",
    "        return np.r_[np.full(window - 1, np.nan),\n",
    "                     np.array(list(map(last_poly9, stride_matrix)))]\n",
    "    else:\n",
    "        index = range(len(origin_array))\n",
    "        fit_params = np.polynomial.Chebyshev.fit(index, origin_array, 9)\n",
    "        y_fit_n = fit_params(index)\n",
    "        return y_fit_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data.csv', parse_dates=True, index_col=0)\n",
    "\n",
    "def hma(array2hma: np.array, n: int = 10):\n",
    "    return talib.WMA(2*talib.WMA(array2hma, int(n/2)) - talib.WMA(array2hma, n), int(math.sqrt(n)))\n",
    "# print(df.columns)\n",
    "# print(df.iloc[0:-50,3].values)\n",
    "df = df[0:-10]\n",
    "df['HMA10'] = hma(df['Close'].values)\n",
    "# df['hma10'][~np.isnan(df['hma10'])]\n",
    "# print(df['hma10'])\n",
    "# print(df[hma10 != np.nan])\n",
    "\n",
    "df['POLYNOMIAL9'] = np.r_[np.full(len(df['HMA10'][np.isnan(df['HMA10'])]),np.nan),rolling_poly9(df['HMA10'][~np.isnan(df['HMA10'])].values,252)]\n",
    "# 1）相关性系数r；2）显著性水平p。\n",
    "# 两者的关系为：当p<0.05(或者0.01)的前提下，才可以参考r值，不能仅仅只看r值。\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna(axis=0, how='any')\n",
    "r,p = stats.pearsonr(df['Close'],df['POLYNOMIAL9'])  # 相关系数和P值\n",
    "# print(df)\n",
    "print(df['POLYNOMIAL9'][-50])\n",
    "print('r=%r, p=%r' %(r, p))\n",
    "r,p = stats.pearsonr(df['HMA10'],df['POLYNOMIAL9'])  # 相关系数和P值\n",
    "print('r=%r, p=%r' %(r, p))\n",
    "# rolling_poly9(df['HMA10'][~np.isnan(df['HMA10'])].values,252)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [4,3,2,1]\n",
    "def inverse_num(series):\n",
    "    # 因为numba不支持enumerate，所以后动计算逆序\n",
    "    count = 0\n",
    "    for i in range(len(series)-1):\n",
    "        for j in range(i+1, len(series)):\n",
    "            if series[i] > series[j]:\n",
    "                count += 1\n",
    "        i += 1\n",
    "    return count\n",
    "\n",
    "inverse_num(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def thresholding_algo(y, lag, threshold, influence):\n",
    "    \"\"\"\n",
    "    Robust peak detection algorithm (using z-scores)\n",
    "    自带鲁棒性极值点识别，利用方差和ZSCORE进行时间序列极值检测。算法源自：\n",
    "    https://stackoverflow.com/questions/22583391/\n",
    "    本实现使用Numba JIT优化，比原版（上面）大约快了500倍。\n",
    "    \"\"\"\n",
    "    signals = np.zeros((3, len(y)), dtype=np.float64)  # 生成3行、len(y)列的全0二维数组\n",
    "    idx_signals = 0\n",
    "    idx_avgFilter = 1\n",
    "    idx_stdFilter = 2\n",
    "\n",
    "    filteredY = np.copy(y)\n",
    "    # signals二维数组的第一行全0\n",
    "    signals[idx_avgFilter, lag-1] = np.mean(y[0:lag])  # signals二维数组第二行首个非0元素计算公式\n",
    "    signals[idx_stdFilter, lag-1] = np.std(y[0:lag])  # signals二维数组第三行首个非0元素计算公式\n",
    "    for i in range(lag, len(y)):\n",
    "        # 把y当前元素与signals第二行前一个元素的差与阈值threshold乘以signals第三行前一个元素的积进行比较\n",
    "        if abs(y[i] - signals[idx_avgFilter, i-1]) > threshold * signals[idx_stdFilter, i-1]:\n",
    "            if y[i] > signals[idx_avgFilter, i-1]:\n",
    "                signals[idx_signals, i] = 1\n",
    "            else:\n",
    "                signals[idx_signals, i] = -1\n",
    "\n",
    "            # filteredY从0~lag-1等于y[0:lag]，从filteredY[lag]开始\n",
    "            # 当前元素值等于影响因子influence和y当前位置元素乘积\n",
    "            # 并加上1-influence乘以filteredY前一位置元素\n",
    "            filteredY[i] = influence * y[i] + (1-influence) * filteredY[i-1]\n",
    "            # signals第二行第i+1个元素等于filteredY前lag个元素的均值\n",
    "            signals[idx_avgFilter, i] = np.mean(filteredY[(i-lag):i])\n",
    "            # signals第三行第i+1个元素等于filteredY前lag个元素的均值\n",
    "            signals[idx_stdFilter, i] = np.std(filteredY[(i-lag):i])\n",
    "        else:\n",
    "            signals[idx_signals, i] = 0\n",
    "            filteredY[i] = y[i]\n",
    "            signals[idx_avgFilter, i] = np.mean(filteredY[(i-lag):i])\n",
    "            signals[idx_stdFilter, i] = np.std(filteredY[(i-lag):i])\n",
    "\n",
    "    return signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag=5\n",
    "threshold=3.5\n",
    "influence=0.5\n",
    "df = pd.read_csv('data/data.csv', parse_dates=True, index_col=0)\n",
    "data = np.array(df.Close)\n",
    "peak = thresholding_algo(data, lag=lag, threshold=threshold, influence=influence)[0,:]\n",
    "print(peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "import pandas as pd\n",
    "import talib\n",
    "\n",
    "df = pd.read_csv('data/data.csv', parse_dates=True, index_col=0)\n",
    "data = np.array(df.Close)\n",
    "\n",
    "\n",
    "def ma_power(data, range_list=range(5, 30)):\n",
    "    def inverse_num(series):\n",
    "        # 计算逆序\n",
    "        count = 0\n",
    "        for i in range(len(series)-1):\n",
    "            for j in range(i+1, len(series)):\n",
    "                if series[i] > series[j]:\n",
    "                    count += 1\n",
    "            i += 1\n",
    "        return count\n",
    "\n",
    "    # 准备收盘价，初始化ma多维数组\n",
    "    ma_np = np.empty((len(data), len(range_list)))\n",
    "    ma_count = 0\n",
    "\n",
    "    # 列向量对应MA5-MA30\n",
    "    for r in range_list:\n",
    "        ma = talib.MA(data, r)\n",
    "        ma_np[:, ma_count] = ma\n",
    "        ma_count += 1\n",
    "\n",
    "    ma_max = max(range_list)\n",
    "    len_range_list = len(range_list)\n",
    "    num = np.zeros(len(data))\n",
    "    ratio = np.zeros(len(data))\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        for i in range(ma_max, len(data)):\n",
    "            num[i] = inverse_num(ma_np[i, :])\n",
    "            ratio[i] = num[i] / (len_range_list * (len_range_list - 1)) * 2\n",
    "\n",
    "    return ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ma_power(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "\n",
    "try:\n",
    "    connection = psycopg2.connect(user=\"postgres\",\n",
    "                                    #   password=\"postgres\",\n",
    "                                      host=\"127.0.0.1\",\n",
    "                                      port=\"5432\",\n",
    "                                      database=\"stock\")\n",
    "\n",
    "    # Create a cursor to perform database operations\n",
    "    cursor = connection.cursor()\n",
    "    # Print PostgreSQL details\n",
    "    print(\"PostgreSQL server information\")\n",
    "    print(connection.get_dsn_parameters(), \"\\n\")\n",
    "    # Executing a SQL query\n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    # Fetch result\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"PostgreSQL connection is closed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "from config.essential import TOKEN\n",
    "\n",
    "\n",
    "pro = ts.pro_api(TOKEN)\n",
    "data = pro.query('stock_basic', exchange='', list_status='L', fields='ts_code,symbol,name,area,industry,list_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "res=date(2020,1,11)-timedelta(days=1)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "from config.essential import DB\n",
    "\n",
    "\n",
    "try:\n",
    "    # Connect to an existing database\n",
    "    connection = psycopg2.connect(user=DB['username'],\n",
    "                                    # password=\"123456\",\n",
    "                                    host=DB['host'],\n",
    "                                    port=DB['port'],\n",
    "                                    database=DB['database'])\n",
    "\n",
    "    # Create a cursor to perform database operations\n",
    "    cursor = connection.cursor()\n",
    "    # Print PostgreSQL details\n",
    "    # print(\"PostgreSQL server information\")\n",
    "    # print(connection.get_dsn_parameters(), \"\\n\")\n",
    "    # Executing a SQL query\n",
    "    # cursor.execute(\"SELECT version();\")\n",
    "    # Fetch result\n",
    "    # record = cursor.fetchone()\n",
    "    # print(\"You are connected to - \", record, \"\\n\")\n",
    "    cursor.execute(data.SQL)\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import backtrader.feeds as btfeeds\n",
    "import pandas as pd\n",
    "# def get_csv_data(pathname, fromdate, todate):\n",
    "#     if isinstance(fromdate, date):\n",
    "#         try:\n",
    "#             fromdate=dt.strptime(fromdate, '%Y-%m-%d')\n",
    "#         except ValueError as error:\n",
    "#             template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "#             message = template.format(type(error).__name__, error.args)\n",
    "#             print (message)\n",
    "#     if isinstance(todate, date):\n",
    "#         try:\n",
    "#             todate=dt.strptime(todate, '%Y-%m-%d')\n",
    "#         except ValueError as error:\n",
    "#             template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "#             message = template.format(type(error).__name__, error.args)\n",
    "#             print (message)\n",
    "#     data = btfeeds.YahooFinanceCSVData(\n",
    "#         dataname=pathname,\n",
    "#         # Do not pass values before this date\n",
    "#         fromdate=fromdate,\n",
    "#         # Do not pass values before this date\n",
    "#         todate=todate,\n",
    "#         # Do not pass values after this date\n",
    "#         reverse=False)\n",
    "#     return data\n",
    "\n",
    "# stockdata = get_csv_data('data/data.csv', '2003-01-01', '2003-12-31')\n",
    "stockdata = pd.read_csv('data/data.csv', header=None, skiprows=1 ,parse_dates=True)\n",
    "print(stockdata.values[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from config.essential import DB\n",
    "token = 'd5810b82a826762185f46bc579ae748553f276e82e6572f9e915482b'\n",
    "pro = ts.pro_api(token)\n",
    "data = pro.query('stock_basic', exchange='', list_status='L', fields='ts_code, symbol, name, area, industry, list_date')\n",
    "# # for ticker in data['ts_code']:\n",
    "# #     print(ticker)\n",
    "# print(data['ts_code'][0])\n",
    "connection = psycopg2.connect(user=\"postgres\",\n",
    "                                      password=\"123456\",\n",
    "                                      host=\"127.0.0.1\",\n",
    "                                      port=\"5432\",\n",
    "                                      database=\"stock\")\n",
    "\n",
    "    # Create a cursor to perform database operations\n",
    "cursor = connection.cursor()\n",
    "query = sql.SQL('CREATE TABLE IF NOT EXISTS {table} (date DATE PRIMARY KEY, open FLOAT4, high FLOAT4, low FLOAT4, close FLOAT4, adjust FLOAT4, volumn INT)').format(table=sql.Identifier(data['ts_code'][0]))\n",
    "cursor.execute(query)\n",
    "connection.commit()\n",
    "query = sql.SQL('INSERT INTO {table} VALUES (%s, %s, %s, %s, %s, %s, %s)').format(table=sql.Identifier(data['ts_code'][0]))\n",
    "print(type(stockdata))\n",
    "print(type(stockdata.values[0,:]))\n",
    "cursor.executemany(query, list(stockdata.itertuples(index=False, name=None)))\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import Error, sql\n",
    "from config.essential import DB\n",
    "db=DB\n",
    "ticker = '000001.SZ'\n",
    "try:\n",
    "    # Connect to an existing database\n",
    "    connection = psycopg2.connect(user=db['username'],\n",
    "                                    password=db['password'],\n",
    "                                    host=db['host'],\n",
    "                                    port=db['port'],\n",
    "                                    database=db['database'])\n",
    "\n",
    "    # Create a cursor to perform database operations\n",
    "    cursor = connection.cursor()\n",
    "    query = sql.SQL('CREATE TABLE IF NOT EXISTS {table} (date DATE PRIMARY KEY, open FLOAT4, high FLOAT4, low FLOAT4, close FLOAT4, adjust FLOAT4, volumn INT)').format(table=sql.Identifier(ticker))\n",
    "    cursor.execute(query)\n",
    "    connection.commit()\n",
    "    query = sql.SQL('SELECT * FROM {table} WHERE DATE BETWEEN %s AND %s ORDER BY {date} ASC').format(table=sql.Identifier(ticker), date=sql.Identifier('date'))\n",
    "    cursor.execute(query, ('2000-01-01', '2003-01-20'))\n",
    "    records = cursor.fetchall()\n",
    "    print(type(records))\n",
    "except (Exception, Error) as error:\n",
    "    print('Error while connecting to PostgreSQL', error)\n",
    "finally:\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print('Query complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if records == []:\n",
    "    print('hello')\n",
    "records = None\n",
    "print(records)\n",
    "print(type(records))\n",
    "if records == None:\n",
    "    print('this is none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.essential import PROXY, DB\n",
    "from datetime import datetime as dt\n",
    "import yfinance as yf\n",
    "from tools.data_yahoo import insert_ticker_data\n",
    "db=DB\n",
    "ticker = '000001.SZ'\n",
    "fromdate='2021-07-01'\n",
    "todate=dt.now().date()\n",
    "data = yf.download(tickers=ticker, start=fromdate, end=todate, proxy=PROXY)\n",
    "print(data)\n",
    "print(type(data))\n",
    "insert_ticker_data(ticker=ticker, data=data, db=db)  # insert data into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data =records[:4]+records[5:])\n",
    "# print(df)\n",
    "# print(type(records[1]))\n",
    "# print(records[for record in records return record[:4]+record[5:]])\n",
    "records = [record[:4]+record[5:] for record in records]\n",
    "print(records)\n",
    "df = pd.DataFrame(data=records)\n",
    "df.columns = ['datetime', 'open', 'high', 'low', 'close', 'volume']\n",
    "df['openinterest'] = 0\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d')\n",
    "df.set_index(keys='datetime', inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def convert_ticker_type(ticker, style):\n",
    "    if style == 'yahoo':  # yfinance接受的股票代码格式\n",
    "        market = re.search('[a-zA-Z]{2}', ticker).group()\n",
    "        code = re.search('\\d{6}', ticker).group()\n",
    "        ticker = '.'.join([code, market.upper()])\n",
    "        return ticker\n",
    "    elif style == 'baostock':  # baostock接受的股票代码模式\n",
    "        market = re.search('[a-zA-Z]{2}', ticker).group()\n",
    "        code = re.search('\\d{6}', ticker).group()\n",
    "        ticker = '.'.join([market.lower(), code])\n",
    "        return ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "tickers = pro.query('stock_basic', exchange='', list_status='L', fields='ts_code, name, area, industry, list_date')\n",
    "# 把列名按照baostock格式进行修改\n",
    "tickers.columns = ['code', 'code_name', 'area', 'industry', 'list_date']\n",
    "code_list = []\n",
    "for ticker in tickers['code']:\n",
    "    code_list.append(convert_ticker_type(ticker, 'baostock'))\n",
    "tickers['code'] = code_list\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_headers import Headers\n",
    "\n",
    "BASEURL = 'https://www.proxyranker.com'\n",
    "URL = 'https://www.proxyranker.com/china/list/'\n",
    "\n",
    "\n",
    "\n",
    "def get_proxy(URL, proxies):\n",
    "    headers = Headers(os=\"win\", headers=True).generate()\n",
    "    response = requests.get(URL, timeout=(20, 20))\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    table = soup.select('body > div:nth-child(4) > div.bl > div.data > table > tr')\n",
    "    for row in table:\n",
    "        ip = row.select('tr > td:nth-child(1)')[0]\n",
    "        port = row.select('tr > td:nth-child(4) > span')[0]\n",
    "        proxies.append(':'.join([ip.string, port.string]))\n",
    "\n",
    "    page_ref = soup.select('body > div:nth-child(4) > div.bl > div > table > tfoot > tr > td > div > a')\n",
    "    if len(page_ref) > 1:\n",
    "        URL = BASEURL + page_ref[1]['href']\n",
    "        get_proxy(URL, proxies)\n",
    "    return proxies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = get_proxy(URL, proxies=[])\n",
    "for proxy in proxies:\n",
    "    try:\n",
    "        response = requests.get('https://finance.yahoo.com/', timeout=5, proxies=dict(https=proxy))\n",
    "        if response.status_code != 200:\n",
    "            proxies.remove(proxy)\n",
    "    except requests.exceptions.Timeout as error:\n",
    "        print(error)\n",
    "print(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baostock as bs\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "\n",
    "#### 登陆系统 ####\n",
    "lg = bs.login()\n",
    "# 显示登陆返回信息\n",
    "print('login respond error_code:'+lg.error_code)\n",
    "print('login respond  error_msg:'+lg.error_msg)\n",
    "fromdate = dt.strptime('2017-01-01', '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "todate = dt.strptime('2017-01-21', '%Y-%m-%d').strftime('%Y-%m-%d')\n",
    "ticker = '000005.SZ'\n",
    "# 获取未复权数据\n",
    "records = bs.query_history_k_data_plus(ticker,\n",
    "        'date,open,high,low,close,volume',\n",
    "        start_date=fromdate, end_date=todate,\n",
    "        frequency='d', adjustflag='3')\n",
    "print('query_history_k_data_plus respond error_code: ', records.error_code)\n",
    "print('query_history_k_data_plus respond  error_msg: ', records.error_msg)\n",
    "data_list = []\n",
    "while (records.error_code == '0') & records.next():\n",
    "    # 获取一条记录，将记录合并在一起\n",
    "    data_list.append(records.get_row_data())\n",
    "result = pd.DataFrame(data_list, columns=records.fields)\n",
    "# 获取复权后数据\n",
    "records = bs.query_history_k_data_plus(ticker,\n",
    "    'close',\n",
    "    start_date=fromdate, end_date=todate,\n",
    "    frequency='d', adjustflag='2')\n",
    "print('query_history_k_data_plus respond error_code: ', records.error_code)\n",
    "print('query_history_k_data_plus respond  error_msg: ', records.error_msg)\n",
    "data_list = []\n",
    "while (records.error_code == '0') & records.next():\n",
    "    # 获取一条记录，将记录合并在一起\n",
    "    data_list.append(records.get_row_data())\n",
    "result['adjust'] = pd.DataFrame(data_list)\n",
    "result = result[['date','open','high','low','close','adjust','volume']]\n",
    "result['date'] = pd.to_datetime(result['date']).dt.date\n",
    "print(type(result['date'][0]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ticker = '000001.SZ'\n",
    "market = re.search('[a-zA-Z]{2}', ticker).group()\n",
    "code = re.search('\\d{6}', ticker).group()\n",
    "\n",
    "tickers = '.'.join([code, market.upper()])\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backtrader as bt\n",
    "import backtrader.feeds as btfeeds\n",
    "ticker = 'data/data.csv'\n",
    "fromdate='2003-01-01'\n",
    "todate='2005-12-31'\n",
    "data = btfeeds.YahooFinanceCSVData(dataname=ticker, fromdate=fromdate, todate=todate, reverse=False)\n",
    "print(type(data))\n",
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "timetable = {'date':['2006-01-01','2007-01-01','2008-01-01','2009-01-01'], 'ratio':[0.7,0.9,0.8,1]}\n",
    "timetable = pd.DataFrame(timetable)\n",
    "# timetable = timetable.append(l2)\n",
    "print(timetable)\n",
    "timetable['date'] = pd.to_datetime(timetable['date'])\n",
    "timetable.set_index(keys='date', inplace=True)\n",
    "print(timetable)\n",
    "fromdate = '2005-05-05'\n",
    "todate = '2006-01-01'\n",
    "fromdate = dt.strptime(fromdate, '%Y-%m-%d')\n",
    "todate = dt.strptime(todate, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from fake_headers import Headers\n",
    "\n",
    "URL = 'https://push2his.eastmoney.com/api/qt/kamt.kline/get?fields1=f1,f3,f5&fields2=f51,f52&klt=101&lmt=5'\n",
    "headers = Headers(os=\"win\", headers=True).generate()\n",
    "response = requests.get(URL, headers=headers)\n",
    "records = response.json() if response and response.status_code == 200 else None\n",
    "records = records['data']['s2n']\n",
    "result = []\n",
    "for record in records:\n",
    "    result.append(record.split(','))\n",
    "result = pd.DataFrame(result, columns=['date', 'net_flowin'])\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "result['net_flowin'] = pd.to_numeric(result['net_flowin'])\n",
    "result.set_index('date', inplace=True)\n",
    "print(result)\n",
    "print(result.sort_values('net_flowin'))\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import baostock as bs\n",
    "lg = bs.login()\n",
    "# 显示登陆返回信息\n",
    "print('login respond error_code:'+lg.error_code)\n",
    "print('login respond  error_msg:'+lg.error_msg)\n",
    "\n",
    "#### 获取交易日信息 ####\n",
    "# 沪港通从2014-11-21开始\n",
    "# 深港通从2016-12-07开始\n",
    "rs = bs.query_trade_dates(start_date='2016-12-07', end_date=dt.today().strftime('%Y-%m-%d'))\n",
    "print('query_trade_dates respond error_code:'+rs.error_code)\n",
    "print('query_trade_dates respond  error_msg:'+rs.error_msg)\n",
    "data_list = []\n",
    "while (rs.error_code == '0') & rs.next():\n",
    "    # 获取一条记录，将记录合并在一起\n",
    "    data_list.append(rs.get_row_data())\n",
    "result = pd.DataFrame(data_list, columns=rs.fields)\n",
    "print(result.head())\n",
    "result = result[result['is_trading_day'] == '1']\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(a, b):\n",
    "    print('a+b=', a+b)\n",
    "    return a+b\n",
    "\n",
    "class Test():\n",
    "    a = run(3,5)\n",
    "    @staticmethod\n",
    "    def bun(self):\n",
    "        self.a += 1\n",
    "        print(self.a)\n",
    "\n",
    "Test.a\n",
    "x = Test()\n",
    "y = Test()\n",
    "print(x.a)\n",
    "print(Test.a)\n",
    "print(y.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_headers import Headers\n",
    "\n",
    "\n",
    "def get_proxy(URL='http://www.xiladaili.com/http'):\n",
    "    headers = Headers(os=\"win\", headers=True).generate()\n",
    "    proxies = []\n",
    "\n",
    "    for i in range(1, 3):\n",
    "        response = requests.get(\"{url}/{i}\".format(url=URL, i=i), headers=headers)\n",
    "        time.sleep(random.uniform(0.1, 2.2))\n",
    "\n",
    "        response = requests.get(URL, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, features='lxml')\n",
    "        tr = soup.select('body > div > div > div > table > tbody > tr')\n",
    "        for td in tr:\n",
    "            if '高匿' in td.select('tr > td:nth-child(3)')[0].text and '天' in td.select('tr > td:nth-child(6)')[0].text:\n",
    "                proxy = td.select('tr > td:nth-child(1)')[0].text\n",
    "                proxies.append(proxy)\n",
    "    print(proxies)\n",
    "    return proxies\n",
    "\n",
    "def check_proxy(proxy, CHECK_URL='http://icanhazip.com'):\n",
    "    headers = Headers(os=\"win\", headers=True).generate()\n",
    "    proxy_dict = {'https': 'https://' + proxy}\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        # 发送测试请求\n",
    "        response = requests.get(CHECK_URL, headers=headers, proxies=proxy_dict, timeout=1)\n",
    "        if response.status_code == 200:\n",
    "            print('有效IP：' + proxy)\n",
    "            with open('xila_https_list.txt', 'a') as f:\n",
    "                f.write(proxy)\n",
    "                f.write('\\n')\n",
    "        else:\n",
    "            print('无效IP：' + proxy)\n",
    "    except:\n",
    "        print('无效IP：' +proxy)\n",
    "\n",
    "\n",
    "proxies = get_proxy()\n",
    "for proxy in proxies:\n",
    "    check_proxy(proxy, CHECK_URL='http://www.yahoo.com')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime as dt\n",
    "from fake_headers import Headers\n",
    "import baostock as bs\n",
    "\n",
    "\n",
    "login = bs.login()\n",
    "# 显示登陆返回信息\n",
    "print('login respond error_code:'+login.error_code)\n",
    "print('login respond  error_msg:'+login.error_msg)\n",
    "\n",
    "#### 获取交易日信息 ####\n",
    "# 2014年11月17日，沪股通启动，总额度为3000亿元人民币，每日额度为130亿元人民币。\n",
    "# 2016年12月5日，深股通启动，不设总额度限制，每日额度为130亿元人民币。\n",
    "# 2018年4月11日，证监会同意将沪股通和深股通每日额度调整为520亿元人民币，自2018年5月1日起生效。\n",
    "# 返回记录有两列 calendar_date & is_trading_day\n",
    "# is_trading_day 值为 0 或 1，字符类型\n",
    "records = bs.query_trade_dates(start_date='2021-10-01', end_date=dt.today().strftime('%Y-%m-%d'))\n",
    "print('query_trade_dates respond error_code:'+records.error_code)\n",
    "print('query_trade_dates respond  error_msg:'+records.error_msg)\n",
    "result = []\n",
    "while (records.error_code == '0') & records.next():\n",
    "    # 获取一条记录，将记录合并在一起\n",
    "    result.append(records.get_row_data())\n",
    "result = pd.DataFrame(result, columns=records.fields)\n",
    "result = result[result['is_trading_day'] == '1']\n",
    "#### 登出系统 ####\n",
    "bs.logout()\n",
    "\n",
    "\n",
    "URL = 'https://push2his.eastmoney.com/api/qt/kamt.kline/get?fields1=f1,f3,f5&fields2=f51,f52&klt=101&lmt='+str(len(result))\n",
    "headers = Headers(os=\"win\", headers=True).generate()\n",
    "response = requests.get(URL, headers=headers)\n",
    "records = response.json() if response and response.status_code == 200 else None\n",
    "\n",
    "if records is None:\n",
    "    print('No records or retrive error!')\n",
    "    exit\n",
    "\n",
    "records = records['data']['s2n']\n",
    "result = []\n",
    "for record in records:\n",
    "    result.append(record.split(','))\n",
    "result = pd.DataFrame(result, columns=['date', 'net_flowin'])\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "result['net_flowin'] = pd.to_numeric(result['net_flowin'])\n",
    "result.set_index('date', inplace=True)\n",
    "\n",
    "# print(result)\n",
    "#             net_flowin\n",
    "# date                  \n",
    "# 2021-08-23   557556.37\n",
    "# 2021-08-24   983928.38\n",
    "# 2021-08-25   758189.81\n",
    "# 2021-08-26   527087.19\n",
    "# 2021-08-27  1022954.70\n",
    "\n",
    "up = []\n",
    "down = []\n",
    "for i in range(3, len(result)):\n",
    "    today_data = result.iloc[0:i+1,:]\n",
    "    today_data = today_data.sort_values(by='net_flowin', ascending=False)\n",
    "    row_num = today_data.shape[0]\n",
    "    up_index = math.ceil(row_num/3) - 1\n",
    "    down_index = math.ceil(row_num*2/3) - 1\n",
    "    up_value = today_data.iloc[up_index].values[0]\n",
    "    down_value = today_data.iloc[down_index].values[0]\n",
    "    up.append(up_value)\n",
    "    down.append(down_value)\n",
    "\n",
    "threshold_dict = {'up_value':up, 'down_value':down}\n",
    "threshold_df = pd.DataFrame(threshold_dict, index=result.index[3:])\n",
    "signal_df = pd.concat([threshold_df, result.iloc[3:]], axis=1)\n",
    "print(signal_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n",
      "login respond error_code:0\n",
      "login respond  error_msg:success\n",
      "query_history_k_data_plus respond error_code:  0\n",
      "query_history_k_data_plus respond  error_msg:  success\n",
      "          date        open        high         low       close    preclose  \\\n",
      "0   2016-01-04  115.090277  115.090277  110.494221  112.068213  115.027317   \n",
      "1   2016-01-05  110.242382  113.705164  109.549826  113.075567  112.068213   \n",
      "2   2016-01-06  112.697809  114.208841  111.375656  113.957003  113.075567   \n",
      "3   2016-01-07  112.068213  112.697809  109.549826  110.242382  113.957003   \n",
      "4   2016-01-08  111.690455  112.571890  106.464802  110.116463  110.242382   \n",
      "..         ...         ...         ...         ...         ...         ...   \n",
      "385 2017-08-02  126.144238  127.645955  125.674951  126.144238  126.050381   \n",
      "386 2017-08-03  125.956523  125.956523  122.389945  122.765375  126.144238   \n",
      "387 2017-08-04  122.859232  122.953089  120.606656  120.794371  122.765375   \n",
      "388 2017-08-07  120.794371  121.545229  120.418942  121.357515  120.794371   \n",
      "389 2017-08-08  121.169800  121.357515  120.418942  120.794371  121.357515   \n",
      "\n",
      "       volume        amount  adjustflag      turn  tradestatus    pctChg  isST  \n",
      "0    42240610  7.544258e+08           1  0.226449            1 -2.572500     0  \n",
      "1    58054793  1.034181e+09           1  0.311228            1  0.898900     0  \n",
      "2    46772653  8.386674e+08           1  0.250745            1  0.779500     0  \n",
      "3    11350479  1.995027e+08           1  0.060849            1 -3.259700     0  \n",
      "4    71918296  1.262105e+09           1  0.385549            1 -0.114200     0  \n",
      "..        ...           ...         ...       ...          ...       ...   ...  \n",
      "385  61644148  8.304336e+08           1  0.219345            1  0.074455     0  \n",
      "386  78581867  1.036842e+09           1  0.279613            1 -2.678569     0  \n",
      "387  63181971  8.180147e+08           1  0.224817            1 -1.605505     0  \n",
      "388  29528429  3.805187e+08           1  0.105069            1  0.466204     0  \n",
      "389  23570298  3.034699e+08           1  0.083869            1 -0.464040     0  \n",
      "\n",
      "[372 rows x 13 columns]\n",
      "logout success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<baostock.data.resultset.ResultData at 0x1fe162fa550>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baostock as bs\n",
    "import pandas  as pd\n",
    "\n",
    "lg = bs.login()\n",
    "# 显示登陆返回信息\n",
    "print('login respond error_code:'+lg.error_code)\n",
    "print('login respond  error_msg:'+lg.error_msg)\n",
    "records = bs.query_history_k_data_plus('sh.600000', 'date,open,high,low,close,preclose,volume,amount,adjustflag,turn,tradestatus,pctChg,isST', start_date='2016-01-01', end_date='2017-08-08', frequency='d', adjustflag='1') # adjustflag 复权状态(1：后复权， 2：前复权，3：不复权）\n",
    "print('query_history_k_data_plus respond error_code: ', records.error_code)\n",
    "print('query_history_k_data_plus respond  error_msg: ', records.error_msg)\n",
    "\n",
    "# data_list = []\n",
    "# while (records.error_code == '0') & records.next():\n",
    "#     # 获取一条记录，将记录合并在一起\n",
    "#     data_list.append(records.get_row_data())\n",
    "# result = pd.DataFrame(data_list, columns=records.fields)\n",
    "# result = result[result.tradestatus == '1']\n",
    "result = records.get_data()\n",
    "result = result.apply(pd.to_numeric, axis=0, errors='ignore')\n",
    "result = result[result.tradestatus == 1]\n",
    "\n",
    "# result = result[['date','open','high','low','close','preclose','volume','amount','adjustflag','turn','tradestatus','pctChg','isST']]\n",
    "# result['date'] = pd.to_datetime(result['date']).dt.date\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "print(result)\n",
    "bs.logout()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "718d91d85e7b59cfcf17c81aa38a885d0985cff083e53af9937fe7d5deb25dec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
