{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import talib\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import math\r\n",
    "import scipy.stats as stats\r\n",
    "# import numba as nb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def strided_app(origin_array: np.ndarray,\r\n",
    "                window: int = 252, step=1) -> np.ndarray:\r\n",
    "    if origin_array.size > window:\r\n",
    "        nrows = ((origin_array.size - window) // step) + 1\r\n",
    "    else:\r\n",
    "        return origin_array\r\n",
    "    n = origin_array.strides[0]\r\n",
    "    return np.lib.stride_tricks.as_strided(origin_array,\r\n",
    "                                           shape=(nrows, window),\r\n",
    "                                           strides=(step * n, n))\r\n",
    "\r\n",
    "def rolling_poly9(origin_array: np.ndarray, window: int = 252) -> np.ndarray:\r\n",
    "    '''\r\n",
    "    一次九项式滚动分解拟合\r\n",
    "    '''\r\n",
    "    index = range(window)\r\n",
    "\r\n",
    "    def last_poly9(array_input):\r\n",
    "        fit_params = np.polynomial.Chebyshev.fit(index, array_input, 9)\r\n",
    "        return fit_params(index)[-1]\r\n",
    "\r\n",
    "    if (len(origin_array) > window):\r\n",
    "        stride_matrix = strided_app(origin_array, window, 1)\r\n",
    "        # numpy.r_[]按照行方向拼接array，list是列向量形式存储，故仅能拼接array\r\n",
    "        # numpy.c_[]按照列方向拼接array\r\n",
    "        # .full()填充ndarray\r\n",
    "        return np.r_[np.full(window - 1, np.nan),\r\n",
    "                     np.array(list(map(last_poly9, stride_matrix)))]\r\n",
    "    else:\r\n",
    "        index = range(len(origin_array))\r\n",
    "        fit_params = np.polynomial.Chebyshev.fit(index, origin_array, 9)\r\n",
    "        y_fit_n = fit_params(index)\r\n",
    "        return y_fit_n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv('data/data.csv', parse_dates=True, index_col=0)\r\n",
    "\r\n",
    "def hma(array2hma: np.array, n: int = 10):\r\n",
    "    return talib.WMA(2*talib.WMA(array2hma, int(n/2)) - talib.WMA(array2hma, n), int(math.sqrt(n)))\r\n",
    "# print(df.columns)\r\n",
    "# print(df.iloc[0:-50,3].values)\r\n",
    "df = df[0:-10]\r\n",
    "df['HMA10'] = hma(df['Close'].values)\r\n",
    "# df['hma10'][~np.isnan(df['hma10'])]\r\n",
    "# print(df['hma10'])\r\n",
    "# print(df[hma10 != np.nan])\r\n",
    "\r\n",
    "df['POLYNOMIAL9'] = np.r_[np.full(len(df['HMA10'][np.isnan(df['HMA10'])]),np.nan),rolling_poly9(df['HMA10'][~np.isnan(df['HMA10'])].values,252)]\r\n",
    "# 1）相关性系数r；2）显著性水平p。\r\n",
    "# 两者的关系为：当p<0.05(或者0.01)的前提下，才可以参考r值，不能仅仅只看r值。\r\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\r\n",
    "df = df.dropna(axis=0, how='any')\r\n",
    "r,p = stats.pearsonr(df['Close'],df['POLYNOMIAL9'])  # 相关系数和P值\r\n",
    "# print(df)\r\n",
    "print(df['POLYNOMIAL9'][-50])\r\n",
    "print('r=%r, p=%r' %(r, p))\r\n",
    "r,p = stats.pearsonr(df['HMA10'],df['POLYNOMIAL9'])  # 相关系数和P值\r\n",
    "print('r=%r, p=%r' %(r, p))\r\n",
    "# rolling_poly9(df['HMA10'][~np.isnan(df['HMA10'])].values,252)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = [4,3,2,1]\r\n",
    "def inverse_num(series):\r\n",
    "    # 因为numba不支持enumerate，所以后动计算逆序\r\n",
    "    count = 0\r\n",
    "    for i in range(len(series)-1):\r\n",
    "        for j in range(i+1, len(series)):\r\n",
    "            if series[i] > series[j]:\r\n",
    "                count += 1\r\n",
    "        i += 1\r\n",
    "    return count\r\n",
    "\r\n",
    "inverse_num(a)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import numba as nb\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "\r\n",
    "@nb.jit(nopython=True)\r\n",
    "def thresholding_algo(y, lag, threshold, influence):\r\n",
    "    \"\"\"\r\n",
    "    Robust peak detection algorithm (using z-scores)\r\n",
    "    自带鲁棒性极值点识别，利用方差和ZSCORE进行时间序列极值检测。算法源自：\r\n",
    "    https://stackoverflow.com/questions/22583391/\r\n",
    "    本实现使用Numba JIT优化，比原版（上面）大约快了500倍。\r\n",
    "    \"\"\"\r\n",
    "    signals = np.zeros((3, len(y)), dtype=np.float64)  # 生成3行、len(y)列的全0二维数组\r\n",
    "    idx_signals = 0\r\n",
    "    idx_avgFilter = 1\r\n",
    "    idx_stdFilter = 2\r\n",
    "\r\n",
    "    filteredY = np.copy(y)\r\n",
    "    # signals二维数组的第一行全0\r\n",
    "    signals[idx_avgFilter, lag-1] = np.mean(y[0:lag])  # signals二维数组第二行首个非0元素计算公式\r\n",
    "    signals[idx_stdFilter, lag-1] = np.std(y[0:lag])  # signals二维数组第三行首个非0元素计算公式\r\n",
    "    for i in range(lag, len(y)):\r\n",
    "        # 把y当前元素与signals第二行前一个元素的差与阈值threshold乘以signals第三行前一个元素的积进行比较\r\n",
    "        if abs(y[i] - signals[idx_avgFilter, i-1]) > threshold * signals[idx_stdFilter, i-1]:\r\n",
    "            if y[i] > signals[idx_avgFilter, i-1]:\r\n",
    "                signals[idx_signals, i] = 1\r\n",
    "            else:\r\n",
    "                signals[idx_signals, i] = -1\r\n",
    "\r\n",
    "            # filteredY从0~lag-1等于y[0:lag]，从filteredY[lag]开始\r\n",
    "            # 当前元素值等于影响因子influence和y当前位置元素乘积\r\n",
    "            # 并加上1-influence乘以filteredY前一位置元素\r\n",
    "            filteredY[i] = influence * y[i] + (1-influence) * filteredY[i-1]\r\n",
    "            # signals第二行第i+1个元素等于filteredY前lag个元素的均值\r\n",
    "            signals[idx_avgFilter, i] = np.mean(filteredY[(i-lag):i])\r\n",
    "            # signals第三行第i+1个元素等于filteredY前lag个元素的均值\r\n",
    "            signals[idx_stdFilter, i] = np.std(filteredY[(i-lag):i])\r\n",
    "        else:\r\n",
    "            signals[idx_signals, i] = 0\r\n",
    "            filteredY[i] = y[i]\r\n",
    "            signals[idx_avgFilter, i] = np.mean(filteredY[(i-lag):i])\r\n",
    "            signals[idx_stdFilter, i] = np.std(filteredY[(i-lag):i])\r\n",
    "\r\n",
    "    return signals"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lag=5\r\n",
    "threshold=3.5\r\n",
    "influence=0.5\r\n",
    "df = pd.read_csv('data/data.csv', parse_dates=True, index_col=0)\r\n",
    "data = np.array(df.Close)\r\n",
    "peak = thresholding_algo(data, lag=lag, threshold=threshold, influence=influence)[0,:]\r\n",
    "print(peak)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import numba as nb\r\n",
    "import pandas as pd\r\n",
    "import talib\r\n",
    "\r\n",
    "df = pd.read_csv('data/data.csv', parse_dates=True, index_col=0)\r\n",
    "data = np.array(df.Close)\r\n",
    "\r\n",
    "\r\n",
    "def ma_power(data, range_list=range(5, 30)):\r\n",
    "    def inverse_num(series):\r\n",
    "        # 计算逆序\r\n",
    "        count = 0\r\n",
    "        for i in range(len(series)-1):\r\n",
    "            for j in range(i+1, len(series)):\r\n",
    "                if series[i] > series[j]:\r\n",
    "                    count += 1\r\n",
    "            i += 1\r\n",
    "        return count\r\n",
    "\r\n",
    "    # 准备收盘价，初始化ma多维数组\r\n",
    "    ma_np = np.empty((len(data), len(range_list)))\r\n",
    "    ma_count = 0\r\n",
    "\r\n",
    "    # 列向量对应MA5-MA30\r\n",
    "    for r in range_list:\r\n",
    "        ma = talib.MA(data, r)\r\n",
    "        ma_np[:, ma_count] = ma\r\n",
    "        ma_count += 1\r\n",
    "\r\n",
    "    ma_max = max(range_list)\r\n",
    "    len_range_list = len(range_list)\r\n",
    "    num = np.zeros(len(data))\r\n",
    "    ratio = np.zeros(len(data))\r\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\r\n",
    "        for i in range(ma_max, len(data)):\r\n",
    "            num[i] = inverse_num(ma_np[i, :])\r\n",
    "            ratio[i] = num[i] / (len_range_list * (len_range_list - 1)) * 2\r\n",
    "\r\n",
    "    return ratio\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(ma_power(data))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import psycopg2\r\n",
    "from psycopg2 import Error\r\n",
    "\r\n",
    "try:\r\n",
    "    connection = psycopg2.connect(user=\"postgres\",\r\n",
    "                                    #   password=\"postgres\",\r\n",
    "                                      host=\"127.0.0.1\",\r\n",
    "                                      port=\"5432\",\r\n",
    "                                      database=\"stock\")\r\n",
    "\r\n",
    "    # Create a cursor to perform database operations\r\n",
    "    cursor = connection.cursor()\r\n",
    "    # Print PostgreSQL details\r\n",
    "    print(\"PostgreSQL server information\")\r\n",
    "    print(connection.get_dsn_parameters(), \"\\n\")\r\n",
    "    # Executing a SQL query\r\n",
    "    cursor.execute(\"SELECT version();\")\r\n",
    "    # Fetch result\r\n",
    "except (Exception, Error) as error:\r\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\r\n",
    "finally:\r\n",
    "    cursor.close()\r\n",
    "    connection.close()\r\n",
    "    print(\"PostgreSQL connection is closed\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tushare as ts\r\n",
    "from config.essential import TOKEN\r\n",
    "\r\n",
    "\r\n",
    "pro = ts.pro_api(TOKEN)\r\n",
    "data = pro.query('stock_basic', exchange='', list_status='L', fields='ts_code,symbol,name,area,industry,list_date')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import date\r\n",
    "from datetime import timedelta\r\n",
    "\r\n",
    "res=date(2020,1,11)-timedelta(days=1)\r\n",
    "print(res)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import psycopg2\r\n",
    "from psycopg2 import Error\r\n",
    "from config.essential import DB\r\n",
    "\r\n",
    "\r\n",
    "try:\r\n",
    "    # Connect to an existing database\r\n",
    "    connection = psycopg2.connect(user=DB['username'],\r\n",
    "                                    # password=\"123456\",\r\n",
    "                                    host=DB['host'],\r\n",
    "                                    port=DB['port'],\r\n",
    "                                    database=DB['database'])\r\n",
    "\r\n",
    "    # Create a cursor to perform database operations\r\n",
    "    cursor = connection.cursor()\r\n",
    "    # Print PostgreSQL details\r\n",
    "    # print(\"PostgreSQL server information\")\r\n",
    "    # print(connection.get_dsn_parameters(), \"\\n\")\r\n",
    "    # Executing a SQL query\r\n",
    "    # cursor.execute(\"SELECT version();\")\r\n",
    "    # Fetch result\r\n",
    "    # record = cursor.fetchone()\r\n",
    "    # print(\"You are connected to - \", record, \"\\n\")\r\n",
    "    cursor.execute(data.SQL)\r\n",
    "\r\n",
    "except (Exception, Error) as error:\r\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\r\n",
    "finally:\r\n",
    "    cursor.close()\r\n",
    "    connection.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import datetime as dt\r\n",
    "import backtrader.feeds as btfeeds\r\n",
    "import pandas as pd\r\n",
    "# def get_csv_data(pathname, fromdate, todate):\r\n",
    "#     if isinstance(fromdate, date):\r\n",
    "#         try:\r\n",
    "#             fromdate=dt.strptime(fromdate, '%Y-%m-%d')\r\n",
    "#         except ValueError as error:\r\n",
    "#             template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\r\n",
    "#             message = template.format(type(error).__name__, error.args)\r\n",
    "#             print (message)\r\n",
    "#     if isinstance(todate, date):\r\n",
    "#         try:\r\n",
    "#             todate=dt.strptime(todate, '%Y-%m-%d')\r\n",
    "#         except ValueError as error:\r\n",
    "#             template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\r\n",
    "#             message = template.format(type(error).__name__, error.args)\r\n",
    "#             print (message)\r\n",
    "#     data = btfeeds.YahooFinanceCSVData(\r\n",
    "#         dataname=pathname,\r\n",
    "#         # Do not pass values before this date\r\n",
    "#         fromdate=fromdate,\r\n",
    "#         # Do not pass values before this date\r\n",
    "#         todate=todate,\r\n",
    "#         # Do not pass values after this date\r\n",
    "#         reverse=False)\r\n",
    "#     return data\r\n",
    "\r\n",
    "# stockdata = get_csv_data('data/data.csv', '2003-01-01', '2003-12-31')\r\n",
    "stockdata = pd.read_csv('data/data.csv', header=None, skiprows=1 ,parse_dates=True)\r\n",
    "print(stockdata.values[0,:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tushare as ts\r\n",
    "import psycopg2\r\n",
    "from psycopg2 import sql\r\n",
    "from config.essential import DB\r\n",
    "token = 'd5810b82a826762185f46bc579ae748553f276e82e6572f9e915482b'\r\n",
    "pro = ts.pro_api(token)\r\n",
    "data = pro.query('stock_basic', exchange='', list_status='L', fields='ts_code, symbol, name, area, industry, list_date')\r\n",
    "# # for ticker in data['ts_code']:\r\n",
    "# #     print(ticker)\r\n",
    "# print(data['ts_code'][0])\r\n",
    "connection = psycopg2.connect(user=\"postgres\",\r\n",
    "                                      password=\"123456\",\r\n",
    "                                      host=\"127.0.0.1\",\r\n",
    "                                      port=\"5432\",\r\n",
    "                                      database=\"stock\")\r\n",
    "\r\n",
    "    # Create a cursor to perform database operations\r\n",
    "cursor = connection.cursor()\r\n",
    "query = sql.SQL('CREATE TABLE IF NOT EXISTS {table} (date DATE PRIMARY KEY, open FLOAT4, high FLOAT4, low FLOAT4, close FLOAT4, adjust FLOAT4, volumn INT)').format(table=sql.Identifier(data['ts_code'][0]))\r\n",
    "cursor.execute(query)\r\n",
    "connection.commit()\r\n",
    "query = sql.SQL('INSERT INTO {table} VALUES (%s, %s, %s, %s, %s, %s, %s)').format(table=sql.Identifier(data['ts_code'][0]))\r\n",
    "print(type(stockdata))\r\n",
    "print(type(stockdata.values[0,:]))\r\n",
    "cursor.executemany(query, list(stockdata.itertuples(index=False, name=None)))\r\n",
    "connection.commit()\r\n",
    "cursor.close()\r\n",
    "connection.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import psycopg2\r\n",
    "from psycopg2 import Error, sql\r\n",
    "from config.essential import DB\r\n",
    "db=DB\r\n",
    "ticker = '000001.SZ'\r\n",
    "try:\r\n",
    "    # Connect to an existing database\r\n",
    "    connection = psycopg2.connect(user=db['username'],\r\n",
    "                                    password=db['password'],\r\n",
    "                                    host=db['host'],\r\n",
    "                                    port=db['port'],\r\n",
    "                                    database=db['database'])\r\n",
    "\r\n",
    "    # Create a cursor to perform database operations\r\n",
    "    cursor = connection.cursor()\r\n",
    "    query = sql.SQL('CREATE TABLE IF NOT EXISTS {table} (date DATE PRIMARY KEY, open FLOAT4, high FLOAT4, low FLOAT4, close FLOAT4, adjust FLOAT4, volumn INT)').format(table=sql.Identifier(ticker))\r\n",
    "    cursor.execute(query)\r\n",
    "    connection.commit()\r\n",
    "    query = sql.SQL('SELECT * FROM {table} WHERE DATE BETWEEN %s AND %s ORDER BY {date} ASC').format(table=sql.Identifier(ticker), date=sql.Identifier('date'))\r\n",
    "    cursor.execute(query, ('2000-01-01', '2003-01-20'))\r\n",
    "    records = cursor.fetchall()\r\n",
    "    print(type(records))\r\n",
    "except (Exception, Error) as error:\r\n",
    "    print('Error while connecting to PostgreSQL', error)\r\n",
    "finally:\r\n",
    "    cursor.close()\r\n",
    "    connection.close()\r\n",
    "    print('Query complete.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if records == []:\r\n",
    "    print('hello')\r\n",
    "records = None\r\n",
    "print(records)\r\n",
    "print(type(records))\r\n",
    "if records == None:\r\n",
    "    print('this is none')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from config.essential import PROXY, DB\r\n",
    "from datetime import datetime as dt\r\n",
    "import yfinance as yf\r\n",
    "from tools.data_yahoo import insert_ticker_data\r\n",
    "db=DB\r\n",
    "ticker = '000001.SZ'\r\n",
    "fromdate='2021-07-01'\r\n",
    "todate=dt.now().date()\r\n",
    "data = yf.download(tickers=ticker, start=fromdate, end=todate, proxy=PROXY)\r\n",
    "print(data)\r\n",
    "print(type(data))\r\n",
    "insert_ticker_data(ticker=ticker, data=data, db=db)  # insert data into db"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# df = pd.DataFrame(data =records[:4]+records[5:])\r\n",
    "# print(df)\r\n",
    "# print(type(records[1]))\r\n",
    "# print(records[for record in records return record[:4]+record[5:]])\r\n",
    "records = [record[:4]+record[5:] for record in records]\r\n",
    "print(records)\r\n",
    "df = pd.DataFrame(data=records)\r\n",
    "df.columns = ['datetime', 'open', 'high', 'low', 'close', 'volume']\r\n",
    "df['openinterest'] = 0\r\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d')\r\n",
    "df.set_index(keys='datetime', inplace=True)\r\n",
    "print(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\r\n",
    "def convert_ticker_type(ticker, style):\r\n",
    "    if style == 'yahoo':  # yfinance接受的股票代码格式\r\n",
    "        market = re.search('[a-zA-Z]{2}', ticker).group()\r\n",
    "        code = re.search('\\d{6}', ticker).group()\r\n",
    "        ticker = '.'.join([code, market.upper()])\r\n",
    "        return ticker\r\n",
    "    elif style == 'baostock':  # baostock接受的股票代码模式\r\n",
    "        market = re.search('[a-zA-Z]{2}', ticker).group()\r\n",
    "        code = re.search('\\d{6}', ticker).group()\r\n",
    "        ticker = '.'.join([market.lower(), code])\r\n",
    "        return ticker"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tushare as ts\r\n",
    "tickers = pro.query('stock_basic', exchange='', list_status='L', fields='ts_code, name, area, industry, list_date')\r\n",
    "# 把列名按照baostock格式进行修改\r\n",
    "tickers.columns = ['code', 'code_name', 'area', 'industry', 'list_date']\r\n",
    "code_list = []\r\n",
    "for ticker in tickers['code']:\r\n",
    "    code_list.append(convert_ticker_type(ticker, 'baostock'))\r\n",
    "tickers['code'] = code_list\r\n",
    "print(tickers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from fake_headers import Headers\r\n",
    "\r\n",
    "BASEURL = 'https://www.proxyranker.com'\r\n",
    "URL = 'https://www.proxyranker.com/china/list/'\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def get_proxy(URL, proxies):\r\n",
    "    headers = Headers(os=\"win\", headers=True).generate()\r\n",
    "    response = requests.get(URL, timeout=(20, 20))\r\n",
    "    soup = BeautifulSoup(response.text)\r\n",
    "    table = soup.select('body > div:nth-child(4) > div.bl > div.data > table > tr')\r\n",
    "    for row in table:\r\n",
    "        ip = row.select('tr > td:nth-child(1)')[0]\r\n",
    "        port = row.select('tr > td:nth-child(4) > span')[0]\r\n",
    "        proxies.append(':'.join([ip.string, port.string]))\r\n",
    "\r\n",
    "    page_ref = soup.select('body > div:nth-child(4) > div.bl > div > table > tfoot > tr > td > div > a')\r\n",
    "    if len(page_ref) > 1:\r\n",
    "        URL = BASEURL + page_ref[1]['href']\r\n",
    "        get_proxy(URL, proxies)\r\n",
    "    return proxies\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "proxies = get_proxy(URL, proxies=[])\r\n",
    "for proxy in proxies:\r\n",
    "    try:\r\n",
    "        response = requests.get('https://finance.yahoo.com/', timeout=5, proxies=dict(https=proxy))\r\n",
    "        if response.status_code != 200:\r\n",
    "            proxies.remove(proxy)\r\n",
    "    except requests.exceptions.Timeout as error:\r\n",
    "        print(error)\r\n",
    "print(proxies)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "import baostock as bs\r\n",
    "import pandas as pd\r\n",
    "from datetime import datetime as dt\r\n",
    "\r\n",
    "#### 登陆系统 ####\r\n",
    "lg = bs.login()\r\n",
    "# 显示登陆返回信息\r\n",
    "print('login respond error_code:'+lg.error_code)\r\n",
    "print('login respond  error_msg:'+lg.error_msg)\r\n",
    "fromdate = dt.strptime('2017-01-01', '%Y-%m-%d').strftime('%Y-%m-%d')\r\n",
    "todate = dt.strptime('2017-01-21', '%Y-%m-%d').strftime('%Y-%m-%d')\r\n",
    "ticker = '000005.SZ'\r\n",
    "# 获取未复权数据\r\n",
    "records = bs.query_history_k_data_plus(ticker,\r\n",
    "        'date,open,high,low,close,volume',\r\n",
    "        start_date=fromdate, end_date=todate,\r\n",
    "        frequency='d', adjustflag='3')\r\n",
    "print('query_history_k_data_plus respond error_code: ', records.error_code)\r\n",
    "print('query_history_k_data_plus respond  error_msg: ', records.error_msg)\r\n",
    "data_list = []\r\n",
    "while (records.error_code == '0') & records.next():\r\n",
    "    # 获取一条记录，将记录合并在一起\r\n",
    "    data_list.append(records.get_row_data())\r\n",
    "result = pd.DataFrame(data_list, columns=records.fields)\r\n",
    "# 获取复权后数据\r\n",
    "records = bs.query_history_k_data_plus(ticker,\r\n",
    "    'close',\r\n",
    "    start_date=fromdate, end_date=todate,\r\n",
    "    frequency='d', adjustflag='2')\r\n",
    "print('query_history_k_data_plus respond error_code: ', records.error_code)\r\n",
    "print('query_history_k_data_plus respond  error_msg: ', records.error_msg)\r\n",
    "data_list = []\r\n",
    "while (records.error_code == '0') & records.next():\r\n",
    "    # 获取一条记录，将记录合并在一起\r\n",
    "    data_list.append(records.get_row_data())\r\n",
    "result['adjust'] = pd.DataFrame(data_list)\r\n",
    "result = result[['date','open','high','low','close','adjust','volume']]\r\n",
    "result['date'] = pd.to_datetime(result['date']).dt.date\r\n",
    "print(type(result['date'][0]))\r\n",
    "print(result)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "login success!\n",
      "login respond error_code:0\n",
      "login respond  error_msg:success\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'strftime'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-edfde21cc578>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'login respond  error_msg:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfromdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2017-01-01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtodate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2017-01-21'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mticker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'000005.SZ'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# 获取未复权数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'strftime'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\r\n",
    "ticker = '000001.SZ'\r\n",
    "market = re.search('[a-zA-Z]{2}', ticker).group()\r\n",
    "code = re.search('\\d{6}', ticker).group()\r\n",
    "\r\n",
    "tickers = '.'.join([code, market.upper()])\r\n",
    "print(tickers)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}